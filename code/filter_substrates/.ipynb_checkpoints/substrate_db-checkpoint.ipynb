{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this script is to get all the unique substrates from a file and then try to filter out co-factors and other co-substrates.<br/><br/>Copyright (C) 2017  Martin Engqvist Lab<br/>This program is free software: you can redistribute it and/or modify<br/>it under the terms of the GNU General Public License as published by<br/>the Free Software Foundation, either version 3 of the License, or<br/>(at your option) any later version.<br/>This program is distributed in the hope that it will be useful,<br/>but WITHOUT ANY WARRANTY; without even the implied warranty of<br/>MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the<br/>GNU General Public License for more details.<br/>You should have received a copy of the GNU General Public License<br/>along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard variables loaded, you are good to go!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from os.path import join, dirname, basename, exists, isdir\n",
    "\n",
    "### Load environmental variables from the project root directory ###\n",
    "# find .env automagically by walking up directories until it's found\n",
    "dotenv_path = find_dotenv()\n",
    "\n",
    "# load up the entries as environment variables\n",
    "load_dotenv(dotenv_path)\n",
    "\n",
    "# now you can get the variables using their names\n",
    "\n",
    "# Check whether a network drive has been specified\n",
    "DATABASE = os.environ.get(\"NETWORK_URL\")\n",
    "if DATABASE == 'None':\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "    #mount network drive here\n",
    "\n",
    "# set up directory paths\n",
    "CURRENT_DIR = os.getcwd()\n",
    "PROJ = dirname(dotenv_path) # project root directory\n",
    "\n",
    "DATA = join(PROJ, 'data') #data directory\n",
    "RAW_EXTERNAL = join(DATA, 'raw_external') # external data raw directory\n",
    "RAW_INTERNAL = join(DATA, 'raw_internal') # internal data raw directory\n",
    "INTERMEDIATE = join(DATA, 'intermediate') # intermediate data directory\n",
    "FINAL = join(DATA, 'final') # final data directory\n",
    "\n",
    "RESULTS = join(PROJ, 'results') # output directory\n",
    "FIGURES = join(RESULTS, 'figures') # figure output directory\n",
    "PICTURES = join(RESULTS, 'pictures') # picture output directory\n",
    "\n",
    "\n",
    "# make folders specific for certain data\n",
    "folder_name = 'brenda_data_2019_1'\n",
    "if folder_name != '':\n",
    "    #make folders if they don't exist\n",
    "    if not exists(join(RAW_EXTERNAL, folder_name)):\n",
    "        os.makedirs(join(RAW_EXTERNAL, folder_name))\n",
    "\n",
    "    if not exists(join(INTERMEDIATE, folder_name)):\n",
    "        os.makedirs(join(INTERMEDIATE, folder_name))\n",
    "\n",
    "    if not exists(join(FINAL, folder_name)):\n",
    "        os.makedirs(join(FINAL, folder_name))\n",
    "\n",
    "print('Standard variables loaded, you are good to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here I want to develop a way to re-use the substrate to molecule conversion\n",
    "The reaseon is that cirpy takes a long time to reference the datbase. I therefore want to locally store the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load up the substrates from BRENDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2 -hydroxyisocaproate',\n",
       " '2-hydroxy-4-methylthiobutanoic acid',\n",
       " '2-hydroxybutyrate',\n",
       " '2-hydroxycaproate',\n",
       " '2-hydroxycaprylate',\n",
       " '2-hydroxyisocaproate',\n",
       " '2-hydroxyisovalerate',\n",
       " '2-hydroxyoctanoate',\n",
       " '2-hydroxypalmitate',\n",
       " '2-hydroxyvalerate',\n",
       " 'alanine',\n",
       " 'an (s)-2-hydroxy carboxylate',\n",
       " 'glycerate',\n",
       " 'glycolate',\n",
       " 'glyoxylate',\n",
       " 'glyoxylate thiohemiacetals',\n",
       " 'homoserine',\n",
       " 'isoleucine',\n",
       " 'lactate',\n",
       " 'leucine',\n",
       " 'lysine',\n",
       " 'mandelate',\n",
       " 'methionine',\n",
       " 'phenylalanine',\n",
       " 'thiol-glyoxylate adducts',\n",
       " 'tryptophan',\n",
       " 'tyrosine',\n",
       " 'valine']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "filepath = join(FINAL, 'brenda_data_2019_1', 'natural_substrates_filtered.json')\n",
    "with open(filepath, 'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "    \n",
    "\n",
    "    \n",
    "def remove_dl(substrate):\n",
    "    '''\n",
    "    Remove D-, L-, DL- and similar from the beginning of substrates\n",
    "    '''\n",
    "    substrate = substrate.lower()\n",
    "    return re.sub('^d-|^l-|^dl-|^\\(r\\)-|^\\(s\\)-', '', substrate)\n",
    "    \n",
    "\n",
    "def get_all_ec():\n",
    "    '''\n",
    "    Get a list of all ec numbers\n",
    "    '''\n",
    "    return data.keys()\n",
    "\n",
    "    \n",
    "def get_substrates(ec):\n",
    "    '''\n",
    "    Obtain a list of all the natural substrates for an ec number\n",
    "    '''\n",
    "    substrate_list = data[ec]['first_substrate']\n",
    "    return sorted(list(set([remove_dl(s) for s in substrate_list])))\n",
    "\n",
    "\n",
    "get_substrates('1.1.3.15')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use cirpy to get teh molecule for each of these. BUT, first we want to check wether we have a cached file. I will be loading up the cached data and potentially adding to it. So to keep the old backups safe I want to make a new backup each day that the script is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test': 'a;klj'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "currentDT = datetime.datetime.now()\n",
    "cached_file_dir = join(INTERMEDIATE, 'brenda_data_2019_1')\n",
    "filename = 'substrate_cache.json'\n",
    "date = '%s-%s-%s' % (currentDT.year, str(currentDT.month).rjust(2, '0'), str(currentDT.day).rjust(2, '0')) # YY-MM-DD\n",
    "\n",
    "\n",
    "def todays_filename():\n",
    "    '''\n",
    "    Get the filename of todays file.\n",
    "    '''\n",
    "    return join(cached_file_dir, '%s_%s' % (date, filename))\n",
    "\n",
    "\n",
    "def most_recent_filename():\n",
    "    '''\n",
    "    Return the filepath of the most recent file.\n",
    "    '''\n",
    "    # first make a list of all available files\n",
    "    file_data = {}\n",
    "    for fi in os.listdir(cached_file_dir):\n",
    "        if fi.endswith(filename):\n",
    "            year, month, day = fi.replace(filename, '').split('-')\n",
    "            \n",
    "            if file_data.get(year) is None:\n",
    "                file_data[year] = {}\n",
    "                \n",
    "            if file_data[year].get(month) is None:\n",
    "                file_data[year][month] = {}\n",
    "                \n",
    "            file_data[year][month][day] = join(cached_file_dir, fi)\n",
    "    \n",
    "    # if there is no file\n",
    "    if file_data == {}:\n",
    "        return None\n",
    "    \n",
    "    max_year = max(file_data.keys())\n",
    "    max_month = max(file_data[max_year].keys())\n",
    "    max_day = max(file_data[max_year][max_month].keys())\n",
    "    \n",
    "    return file_data[max_year][max_month][max_day]\n",
    "            \n",
    "\n",
    "def open_file(filepath):\n",
    "    '''\n",
    "    Open up the json file and return data structure\n",
    "    '''\n",
    "    with open(filepath, 'r') as f:\n",
    "        data = json.loads(f.read())\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_data(data):\n",
    "    '''\n",
    "    Save data to todays file.\n",
    "    '''\n",
    "    filepath = todays_filename()\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(json.dumps(data))\n",
    "\n",
    "    \n",
    "def load_data():\n",
    "    '''\n",
    "    Load up existing substrate to smile data\n",
    "    '''\n",
    "    # if a file from today exists open it up\n",
    "    filepath = todays_filename()\n",
    "    if exists(filepath):\n",
    "        return open_file(filepath)\n",
    "    \n",
    "    # if no file exists from today then make a copy of the most recent file\n",
    "    else:\n",
    "        old_filepath = most_recent_filename()\n",
    "        \n",
    "        if old_filepath is None:\n",
    "            data = {}\n",
    "        \n",
    "        else:\n",
    "            data = open_file(old_filepath) # get most recent data\n",
    "\n",
    "        save_data(data) # save into todays filename\n",
    "        return data\n",
    "\n",
    "data = load_data()\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets' see how many substrates we are talking about for all of BRENDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique substrates in BRENDA: 8461\n"
     ]
    }
   ],
   "source": [
    "all_substrates = set([])\n",
    "for ec in get_all_ec():\n",
    "    all_substrates.update(get_substrates(ec))\n",
    "    \n",
    "print('Unique substrates in BRENDA: %s' % len(all_substrates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "Now convert these in batches of 100"
=======
    "Now convert these and save to file for every 100 completed ones"
>>>>>>> edbe1e57616a6695d27a895d9f483520aaf657e7
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n"
     ]
    }
   ],
>>>>>>> edbe1e57616a6695d27a895d9f483520aaf657e7
   "source": [
    "import cirpy\n",
    "\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "counter = 0\n",
    "for name in all_substrates:\n",
<<<<<<< HEAD
=======
    "    counter += 1\n",
    "    \n",
>>>>>>> edbe1e57616a6695d27a895d9f483520aaf657e7
    "    if name not in data.keys():\n",
    "        data[name] = cirpy.resolve(name, 'smiles')\n",
    "        \n",
    "    if counter % 100 == 0:\n",
<<<<<<< HEAD
=======
    "        print(counter)\n",
>>>>>>> edbe1e57616a6695d27a895d9f483520aaf657e7
    "        save_data(data)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
